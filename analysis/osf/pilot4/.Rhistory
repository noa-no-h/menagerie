affect_data = data %>%
filter(task_name == "affect heuristic")%>%
mutate(choice = as.numeric(choice))
summary_affect_data <- affect_data %>%
group_by(condition) %>%
mutate(condition = factor(condition, levels = c("With passage", "without passage"))) %>%
summarize(
mean_choice = mean(choice),
se_choice = se(choice),
count = n()
)
ggplot(summary_affect_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice), width = 0.2) +
labs(title = "Affect", x = "Condition", y = "How beneficial is natural gas") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom()+
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
affect_analysis = brm(choice ~ factor,
data = affect_data,
save_pars = save_pars(group = F),
prior = default_priors)
summarise_draws(affect_analysis)
check_divergences(affect_analysis$fit)
summary(affect_analysis)
hdi(affect_analysis)
# Hindsight ----
hindsight_data = data %>%
filter(task_name == "hindsight effect")%>%
filter(stimulus != "comprehension") %>%
mutate(choice = as.numeric(choice))
summary_hindsight_data <- hindsight_data %>%
group_by(condition) %>%
mutate(condition = factor(condition, levels = c("knowledge of outcome", "no knowledge of outcome"))) %>%
summarize(
mean_choice = mean(choice),
se_choice = se(choice),
count = n()
)
ggplot(summary_hindsight_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice), width = 0.2) +
labs(title = "Hindsight", x = "Condition", y = "Percent Likelihood of British Victory") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom()+
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
hindsight_analysis = brm(choice ~ factor,
data = hindsight_data,
save_pars = save_pars(group = F),
prior = default_priors)
summary(hindsight_analysis)
hdi(hindsight_analysis)
# Order effect ----
primacy_data <- data %>%
filter(task_name == "primacy order") %>%
filter(choice != "")%>%
mutate(choice = ifelse(choice == "car1",
"chose primacy car",
"chose other car")) %>%
mutate(choice_binary = as.numeric(choice == "chose primacy car"))%>%
mutate(condition = factor(condition, levels = c("Factor-Included", "Factor-Excluded"), labels = c('experience', 'control')))
summary_primacy_data <- primacy_data %>%
group_by(condition) %>%
summarize(
mean_choice = mean(choice_binary),
se_choice = se.prop(choice_binary),
count = n()
)
ggplot(summary_primacy_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
labs(title = "Choices of the primacy car", x = "Condition", y = "Percent who chose primacy car") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom() +
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
primacy_analysis = brm(choice_binary ~ condition,
data = primacy_data,
family = 'bernoulli',
save_pars = save_pars(group = F),
prior = default_priors)
summary(primacy_analysis)
hdi(primacy_analysis, effects = 'all')
# Status quo ----
#When subjects were told the status quo,
#were they more likely to recommend the 70/30 allocation?
status_quo_data <- data %>%
filter(task_name == "status_quo") %>%
filter(stimulus != "comprehension") %>%
mutate(choice = ifelse(auxiliary_info1 == "Allocate 50% to auto safety and 50% to highway safety status quo: 50/50",
"status quo",
choice)) %>%
mutate(choice_binary = as.numeric(choice == "status quo"))%>%
mutate(condition = factor(condition, levels = c("Factor-Included", "Factor-Excluded")))
summary_status_quo_data <- status_quo_data %>%
group_by(condition) %>%
summarize(
mean_choice = mean(choice_binary),
se_choice = se.prop(choice_binary),
count = n()
)
ggplot(summary_status_quo_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
labs(title = "Choices to continue the status quo", x = "Condition", y = "Percent subjects who recommended the status quo") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom() +
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
status_quo_analysis = brm(choice_binary ~ condition,
data = status_quo_data,
family = 'bernoulli',
save_pars = save_pars(group = F),
prior = default_priors)
summary(status_quo_analysis)
hdi(status_quo_analysis, effects = 'all')
# Sunk cost ----
sunk_cost_data <- data %>%
filter(task_name == "sunk_cost2 effect") %>%
mutate(switched = choice == "Don't Continue Investing",
switched.num = as.numeric(switched))
percentage_sunk_cost_data <- sunk_cost_data %>%
group_by(condition) %>%
mutate(condition = factor(condition, levels = c("Sunk Cost", "No Sunk Cost"))) %>%
summarize(
total_in_condition = n(),  # Total number of subjects in each condition
switched_count = sum(choice == "Don't Continue Investing")  # Count who chose "Solar-powered pump"
) %>%
mutate(percentage_switched = (switched_count / total_in_condition) * 100)
ggplot(percentage_sunk_cost_data, aes(x = condition, y = percentage_switched, fill = condition)) +
geom_bar(stat = "identity") +
labs(title = "Percentage Who Stopped Investing", x = "Condition", y = "Percentage of Choices to Stop Investing") +
geom_text(aes(label = paste0("n=", total_in_condition)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom()+
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
sunk_cost_analysis = brm(switched.num ~ condition,
data = sunk_cost_data,
family = 'bernoulli',
save_pars = save_pars(group = F),
prior = default_priors)
summary(sunk_cost_analysis)
hdi(sunk_cost_analysis, effects = 'all')
# Save image --------------------------------------------------------------
save.image('pilot3_output.rdata')
rm(list=ls())
# Setup -------------------------------------------------------------------
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'lme4', 'lmerTest', 'tidyverse', 'RColorBrewer', 'afex', 'this.path', 'brms', 'bayestestR')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
theme_update(strip.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
plot.background = element_blank(),
axis.text=element_text(size=18, colour = "black"),
axis.title=element_text(size=24, face = "bold"),
axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"),
legend.text = element_text(size = 18),
plot.title = element_text(size = 26, face = "bold", vjust = 1),
panel.margin = unit(1.0, "lines"),
plot.margin = unit(c(0.5,  0.5, 0.5, 0.5), "lines"),
axis.line = element_line(colour = "black", size = 2),
axis.ticks = element_line(color = 'black', size = 3),
axis.ticks.length = unit(.25, 'cm')
)
theme_black = function(base_size = 12, base_family = "") {
theme_grey(base_size = base_size, base_family = base_family) %+replace%
theme(
# Specify axis options
axis.line = element_blank(),
axis.text.x = element_text(size = 12, color = "white", lineheight = 0.9),
axis.text.y = element_text(size = 12, color = "white", lineheight = 0.9),
axis.ticks = element_line(color = "white", size  =  0.2),
axis.title.x = element_text(size = 18, color = "white", margin = margin(0, 10, 0, 0)),
axis.title.y = element_text(size = 18, color = "white", angle = 90, margin = margin(0, 10, 0, 0)),
axis.ticks.length = unit(0.3, "lines"),
# Specify legend options
legend.background = element_rect(color = NA, fill = "black"),
legend.key = element_rect(color = "white",  fill = "black"),
legend.key.size = unit(1.2, "lines"),
legend.key.height = NULL,
legend.key.width = NULL,
legend.text = element_text(size = base_size*0.8, color = "white"),
legend.title = element_text(size = base_size*0.8, face = "bold", hjust = 0, color = "white"),
legend.position = "right",
legend.text.align = NULL,
legend.title.align = NULL,
legend.direction = "vertical",
legend.box = NULL,
# Specify panel options
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
panel.border = element_rect(fill = NA, color = "white"),
# Specify facetting options
strip.background = element_rect(fill = "grey30", color = "grey10"),
strip.text.x = element_text(size = base_size*0.8, color = "white"),
strip.text.y = element_text(size = base_size*0.8, color = "white",angle = -90),
# Specify plot options
plot.background = element_rect(color = "black", fill = "black"),
plot.title = element_text(size = base_size*1.2, color = "white"),
plot.margin = unit(rep(1, 4), "lines")
)
}
se = function(x) {return(sd(x, na.rm = T) / sqrt(sum(!is.na(x))))}
se.prop = function(x) {return(sqrt(mean(x, na.rm = T) * (1-mean(x, na.rm = T)) / sum(!is.na(x))))}
# Load data ---------------------------------------------------------------
fields = c('Judgment and decision-making',
'Cognitive psychology',
'Social psychology',
'Developmental psychology',
'Psychology (other)',
'Behavioral economics',
'Economics (other)',
'Other')
df = read.csv('pilot4_data.csv', header = T) %>%
mutate(Progress = as.numeric(Progress)) %>%
filter(DistributionChannel == 'anonymous', Progress >= 90) %>%
select(Subject = ResponseId,
Role = Q11,
Field = Q24,
Gender = q27,
Age = Q28,
starts_with('heuristic')) %>%
mutate(Role.fac = factor(Role, c('Graduate student', 'Postdoc', 'Assistant Professor', 'Associate Professor', 'Full Professor', 'Not in academia', 'Other')),
Gender.fac = factor(Gender, c('Man', 'Woman', 'Some other way')),
Age = as.numeric(Age),
Field.fac = factor(Field, fields))
for (field in fields) {
df = df %>% mutate("{field}" := grepl(field, df$Field, fixed = T))
}
heuristic_cols = 6:22
heuristic_labels = c('Extremely unlikely', 'Moderately unlikely', 'Slightly unlikely', 'Neither likely nor unlikely', 'Slightly likely', 'Moderately likely', 'Extremely likely')
for (i in heuristic_cols) {
df[,i] = factor(df[,i], heuristic_labels, 1:length(heuristic_labels))
}
heuristic_names = c("Anchoring", "Availability heuristic", "Belief bias", "Causal judgment: Abnormal selection", "Decoy effect", "DRM effect", "Halo effect", "Hindsight bias", "Illusion of truth", "Imaginability bias", "Mere exposure effect", "Omission effect in moral judgment", "Recognition heuristic", "Reference price effect", "Representativeness heuristic", "Status quo bias", "Sunk cost bias")
df.long = df %>%
pivot_longer(cols = all_of(heuristic_cols),
names_to = "heuristic_index",
values_to = "heuristic_prediction") %>%
mutate(heuristic_name = factor(heuristic_index, paste0("heuristic_", 1:17), heuristic_names),
heuristic_prediction = as.numeric(heuristic_prediction)) %>%
filter(heuristic_name != 'Imaginability bias') # we ended up dropping this from our set of heuristics/biases after running this pilot because we could not replicate the effect
# Sample details ----------------------------------------------------------
nrow(df) # number of subjects
table(df$Role.fac) # split by academic position
# analyze average overall response, aggregating across heuristics
mean(df.long$heuristic_prediction, na.rm = T)
load('../pilot1/pilot1_alltasks.rdata')
load('../pilot2/pilot2_alltasks.rdata')
all_data_introspection_experience = all_data_introspection_experience_pilot1 %>%
rbind(all_data_introspection_experience_pilot2)
all_bytask_introspection_experience = all_data_introspection_experience %>%
group_by(task_name) %>%
summarize(task_cor = cor(introspect_rating, effect_size_range))
df.byheuristic.filt = df.byheuristic %>%
filter(!(heuristic_name %in% c('DRM effect', 'Hindsight bias', 'Status quo bias', 'Sunk cost bias')))
# split by heuristic
df.byheuristic = df.long %>%
group_by(heuristic_name) %>%
summarize(mean_prediction = mean(heuristic_prediction, na.rm = T),
se_prediction = se(heuristic_prediction),
pct.high.predictions = mean(heuristic_prediction >= 6, na.rm = T),
pct.low.predictions = mean(heuristic_prediction <= 2, na.rm = T),
test.t = t.test(heuristic_prediction, mu = 4)$statistic,
test.df = t.test(heuristic_prediction, mu = 4)$parameter,
test.p = t.test(heuristic_prediction, mu = 4)$p.value)
ggplot(df.byheuristic, aes(x = heuristic_name, y = mean_prediction)) +
geom_jitter(data = df.long, aes(y = heuristic_prediction),
width = 0, alpha = 0.5, height = 0.2) +
geom_point(size = 5, color = 'red') +
geom_errorbar(aes(ymin = mean_prediction - 1.96*se_prediction,
ymax = mean_prediction + 1.96*se_prediction),
width = 0.2, color = 'red') +
geom_hline(yintercept = 4, linetype = 'dashed') +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
scale_y_continuous(limits = c(1,7), breaks = c(1,7), labels = c('Extremely unlikely', 'Extremely likely')) +
labs(x = '', y = 'Prediction')
# split by subject
df.bysubject = df.long %>%
group_by(Subject) %>%
summarize(
mean.prediction = mean(heuristic_prediction, na.rm = T),
se.prediction = se(heuristic_prediction),
any.above.midpoint = any(heuristic_prediction > 4, na.rm = T),
prediction.range = range(heuristic_prediction,na.rm = T)[2] - range(heuristic_prediction, na.rm = T)[1]) %>%
filter(!is.infinite(prediction.range))
load('../pilot1/pilot1_alltasks.rdata')
load('../pilot2/pilot2_alltasks.rdata')
all_data_introspection_experience = all_data_introspection_experience_pilot1 %>%
rbind(all_data_introspection_experience_pilot2)
all_bytask_introspection_experience = all_data_introspection_experience %>%
group_by(task_name) %>%
summarize(task_cor = cor(introspect_rating, effect_size_range))
df.byheuristic.filt = df.byheuristic %>%
filter(!(heuristic_name %in% c('DRM effect', 'Hindsight bias', 'Status quo bias', 'Sunk cost bias')))
df.byheuristic.filt$actual_cor = all_bytask_introspection_experience$task_cor
df.byheuristic.filt$actual_diff = all_bytask_introspection_both$task_diff
ggplot(df.byheuristic.filt, aes(x = actual_cor, y = mean_prediction)) +
geom_point() +
geom_smooth(method = 'lm')
analysis.byheuristic.1 = brm(mean_prediction ~ actual_cor,
df.byheuristic.filt %>% mutate(mean_prediction = scale(mean_prediction),
actual_cor = scale(actual_cor)),
prior = set_prior("normal(0,1)", class = 'b'),
save_pars = save_pars(group = F))
ggplot(df.byheuristic.filt, aes(x = actual_diff, y = mean_prediction)) +
geom_point() +
geom_smooth(method = 'lm')
df.byheuristic.filt = df.byheuristic %>%
filter(!(heuristic_name %in% c('DRM effect', 'Hindsight bias', 'Status quo bias', 'Sunk cost bias')))
df.byheuristic.filt$actual_cor = all_bytask_introspection_experience$task_cor
ggplot(df.byheuristic.filt, aes(x = actual_cor, y = mean_prediction)) +
geom_point() +
geom_smooth(method = 'lm')
rm(list=ls())
# Setup -------------------------------------------------------------------
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'lme4', 'lmerTest', 'tidyverse', 'RColorBrewer', 'afex', 'this.path', 'brms', 'bayestestR')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
theme_update(strip.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
plot.background = element_blank(),
axis.text=element_text(size=18, colour = "black"),
axis.title=element_text(size=24, face = "bold"),
axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"),
legend.text = element_text(size = 18),
plot.title = element_text(size = 26, face = "bold", vjust = 1),
panel.margin = unit(1.0, "lines"),
plot.margin = unit(c(0.5,  0.5, 0.5, 0.5), "lines"),
axis.line = element_line(colour = "black", size = 2),
axis.ticks = element_line(color = 'black', size = 3),
axis.ticks.length = unit(.25, 'cm')
)
theme_black = function(base_size = 12, base_family = "") {
theme_grey(base_size = base_size, base_family = base_family) %+replace%
theme(
# Specify axis options
axis.line = element_blank(),
axis.text.x = element_text(size = 12, color = "white", lineheight = 0.9),
axis.text.y = element_text(size = 12, color = "white", lineheight = 0.9),
axis.ticks = element_line(color = "white", size  =  0.2),
axis.title.x = element_text(size = 18, color = "white", margin = margin(0, 10, 0, 0)),
axis.title.y = element_text(size = 18, color = "white", angle = 90, margin = margin(0, 10, 0, 0)),
axis.ticks.length = unit(0.3, "lines"),
# Specify legend options
legend.background = element_rect(color = NA, fill = "black"),
legend.key = element_rect(color = "white",  fill = "black"),
legend.key.size = unit(1.2, "lines"),
legend.key.height = NULL,
legend.key.width = NULL,
legend.text = element_text(size = base_size*0.8, color = "white"),
legend.title = element_text(size = base_size*0.8, face = "bold", hjust = 0, color = "white"),
legend.position = "right",
legend.text.align = NULL,
legend.title.align = NULL,
legend.direction = "vertical",
legend.box = NULL,
# Specify panel options
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
panel.border = element_rect(fill = NA, color = "white"),
# Specify facetting options
strip.background = element_rect(fill = "grey30", color = "grey10"),
strip.text.x = element_text(size = base_size*0.8, color = "white"),
strip.text.y = element_text(size = base_size*0.8, color = "white",angle = -90),
# Specify plot options
plot.background = element_rect(color = "black", fill = "black"),
plot.title = element_text(size = base_size*1.2, color = "white"),
plot.margin = unit(rep(1, 4), "lines")
)
}
se = function(x) {return(sd(x, na.rm = T) / sqrt(sum(!is.na(x))))}
se.prop = function(x) {return(sqrt(mean(x, na.rm = T) * (1-mean(x, na.rm = T)) / sum(!is.na(x))))}
# Load data ---------------------------------------------------------------
fields = c('Judgment and decision-making',
'Cognitive psychology',
'Social psychology',
'Developmental psychology',
'Psychology (other)',
'Behavioral economics',
'Economics (other)',
'Other')
df = read.csv('pilot4_data.csv', header = T) %>%
mutate(Progress = as.numeric(Progress)) %>%
filter(DistributionChannel == 'anonymous', Progress >= 90) %>%
select(Subject = ResponseId,
Role = Q11,
Field = Q24,
Gender = q27,
Age = Q28,
starts_with('heuristic')) %>%
mutate(Role.fac = factor(Role, c('Graduate student', 'Postdoc', 'Assistant Professor', 'Associate Professor', 'Full Professor', 'Not in academia', 'Other')),
Gender.fac = factor(Gender, c('Man', 'Woman', 'Some other way')),
Age = as.numeric(Age),
Field.fac = factor(Field, fields))
for (field in fields) {
df = df %>% mutate("{field}" := grepl(field, df$Field, fixed = T))
}
heuristic_cols = 6:22
heuristic_labels = c('Extremely unlikely', 'Moderately unlikely', 'Slightly unlikely', 'Neither likely nor unlikely', 'Slightly likely', 'Moderately likely', 'Extremely likely')
for (i in heuristic_cols) {
df[,i] = factor(df[,i], heuristic_labels, 1:length(heuristic_labels))
}
heuristic_names = c("Anchoring", "Availability heuristic", "Belief bias", "Causal judgment: Abnormal selection", "Decoy effect", "DRM effect", "Halo effect", "Hindsight bias", "Illusion of truth", "Imaginability bias", "Mere exposure effect", "Omission effect in moral judgment", "Recognition heuristic", "Reference price effect", "Representativeness heuristic", "Status quo bias", "Sunk cost bias")
df.long = df %>%
pivot_longer(cols = all_of(heuristic_cols),
names_to = "heuristic_index",
values_to = "heuristic_prediction") %>%
mutate(heuristic_name = factor(heuristic_index, paste0("heuristic_", 1:17), heuristic_names),
heuristic_prediction = as.numeric(heuristic_prediction)) %>%
filter(heuristic_name != 'Imaginability bias') # we ended up dropping this from our set of heuristics/biases after running this pilot because we could not replicate the effect
# Sample details ----------------------------------------------------------
nrow(df) # number of subjects
table(df$Role.fac) # split by academic position
# Analyze heuristic data --------------------------------------------------
# analyze average overall response, aggregating across heuristics
mean(df.long$heuristic_prediction, na.rm = T)
analysis.overall = brm(heuristic_prediction ~ 1 + (1 | Subject) + (1 | heuristic_name),
df.long)
summary(analysis.overall)
hdi(analysis.overall)
# split by heuristic
df.byheuristic = df.long %>%
group_by(heuristic_name) %>%
summarize(mean_prediction = mean(heuristic_prediction, na.rm = T),
se_prediction = se(heuristic_prediction),
pct.high.predictions = mean(heuristic_prediction >= 6, na.rm = T),
pct.low.predictions = mean(heuristic_prediction <= 2, na.rm = T),
test.t = t.test(heuristic_prediction, mu = 4)$statistic,
test.df = t.test(heuristic_prediction, mu = 4)$parameter,
test.p = t.test(heuristic_prediction, mu = 4)$p.value)
ggplot(df.byheuristic, aes(x = heuristic_name, y = mean_prediction)) +
geom_jitter(data = df.long, aes(y = heuristic_prediction),
width = 0, alpha = 0.5, height = 0.2) +
geom_point(size = 5, color = 'red') +
geom_errorbar(aes(ymin = mean_prediction - 1.96*se_prediction,
ymax = mean_prediction + 1.96*se_prediction),
width = 0.2, color = 'red') +
geom_hline(yintercept = 4, linetype = 'dashed') +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
scale_y_continuous(limits = c(1,7), breaks = c(1,7), labels = c('Extremely unlikely', 'Extremely likely')) +
labs(x = '', y = 'Prediction')
# split by subject
df.bysubject = df.long %>%
group_by(Subject) %>%
summarize(
mean.prediction = mean(heuristic_prediction, na.rm = T),
se.prediction = se(heuristic_prediction),
any.above.midpoint = any(heuristic_prediction > 4, na.rm = T),
prediction.range = range(heuristic_prediction,na.rm = T)[2] - range(heuristic_prediction, na.rm = T)[1]) %>%
filter(!is.infinite(prediction.range))
hist(df.bysubject$prediction.range)
mean(df.bysubject$prediction.range)
mean(df.bysubject$mean.prediction > 4)
mean(df.bysubject$any.above.midpoint, na.rm = T)
# Compare to results of pilots 1 & 2 --------------------------------------
load('../pilot1/pilot1_alltasks.rdata')
load('../pilot2/pilot2_alltasks.rdata')
all_data_introspection_experience = all_data_introspection_experience_pilot1 %>%
rbind(all_data_introspection_experience_pilot2)
all_bytask_introspection_experience = all_data_introspection_experience %>%
group_by(task_name) %>%
summarize(task_cor = cor(introspect_rating, effect_size_range))
df.byheuristic.filt = df.byheuristic %>%
filter(!(heuristic_name %in% c('DRM effect', 'Hindsight bias', 'Status quo bias', 'Sunk cost bias')))
df.byheuristic.filt$actual_cor = all_bytask_introspection_experience$task_cor
ggplot(df.byheuristic.filt, aes(x = actual_cor, y = mean_prediction)) +
geom_point() +
geom_smooth(method = 'lm')
analysis.byheuristic.1 = brm(mean_prediction ~ actual_cor,
df.byheuristic.filt %>% mutate(mean_prediction = scale(mean_prediction),
actual_cor = scale(actual_cor)),
prior = set_prior("normal(0,1)", class = 'b'),
save_pars = save_pars(group = F))
analysis.byheuristic = brm(mean_prediction ~ actual_cor,
df.byheuristic.filt %>% mutate(mean_prediction = scale(mean_prediction),
actual_cor = scale(actual_cor)),
prior = set_prior("normal(0,1)", class = 'b'),
save_pars = save_pars(group = F))
summary(analysis.byheuristic)
hdi(analysis.byheuristic)
save.image('pilot4_output.rdata')
summary(analysis.overall)
hdi(analysis.overall)
