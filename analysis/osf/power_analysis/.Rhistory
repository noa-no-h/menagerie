number_of_images_diff = number_of_images_A - number_of_images_B,
writing_space_size_diff = writing_space_size_A - writing_space_size_B,
paper_thickness_diff = paper_thickness_A - paper_thickness_B)
require(tidyverse)
data.scaled = data %>%
mutate(width_diff = width_A - width_B,
height_diff = height_A - height_B,
number_of_images_diff = number_of_images_A - number_of_images_B,
writing_space_size_diff = writing_space_size_A - writing_space_size_B,
paper_thickness_diff = paper_thickness_A - paper_thickness_B)
View(data.scaled)
range(c(1,2,3,4), c(0,1))
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
data.scaled = data %>%
mutate(width_diff = range01(width_A - width_B),
height_diff = range01(height_A - height_B),
number_of_images_diff = range01(number_of_images_A - number_of_images_B),
writing_space_size_diff = range01(writing_space_size_A - writing_space_size_B),
paper_thickness_diff = range01(paper_thickness_A - paper_thickness_B))
View(data.scaled)
test = glm(choice ~ width_diff + height_diff + number_of_images_diff + writing_space_size_diff + paper_thickness_diff)
test = glm(choice ~ width_diff + height_diff + number_of_images_diff + writing_space_size_diff + paper_thickness_diff,
data.scaled)
test = glm(choice ~ width_diff + height_diff + number_of_images_diff + writing_space_size_diff + paper_thickness_diff,
data.scaled,
family = 'binomial')
test
summary(test)
test$coefficients
exp(test$coefficients)
rescale_to_sum_one <- function(vec) {
vec / sum(vec)
}
rescale_to_sum_one(test$coefficients)
rescale_to_sum_one(exp(test$coefficients))
# Calculate sample size
result = power.t.test(delta = 0.4, sd = 1, sig.level = 0.05, power = 0.80, type = "two.sample", alternative = 'one.sided')
result$n * 4/3 * 2
# Calculate sample size
result = power.t.test(delta = 0.2, sd = 1, sig.level = 0.05, power = 0.80, type = "two.sample", alternative = 'one.sided')
result$n * 4/3 * 2
# Calculate sample size
result = power.t.test(delta = 0.25, sd = 1, sig.level = 0.05, power = 0.80, type = "two.sample", alternative = 'one.sided')
result$n * 4/3 * 2
load("/Users/am9578/My Drive/Psychology/Projects/ma_choice/git3_pristine_osf/data-analysis/home-fixed/analysis_output.rdata")
summary(lm(scale(weight.accuracy.averaged) ~ scale(actual.inv.temp), data = df.demo.filt))
summary(lm(scale(weight.accuracy.averaged) ~ scale(actual.model.loo.readable), data = df.demo.filt))
summary(lm(scale(weight.accuracy.actual) ~ scale(actual.model.loo.readable), data = df.demo.filt))
observer_coefficient_mean
load("/Users/am9578/My Drive/Psychology/Projects/short-meditation-introspection/experiments/v1/real1/analysis_output.rdata")
# for NIH reporting
nrow(df.demo)
sum(df.demo$race.fac == 'White', na.rm = T)
nrow(df.demo[grep("Hispanic", df.demo$race), ])
# Setup -------------------------------------------------------------------
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'lme4', 'lmerTest', 'tidyverse', 'RColorBrewer', 'afex', 'this.path', 'scales', 'magrittr', 'jsonlite')
p_load(char = pkg.names)
setwd(here())
theme_update(strip.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
plot.background = element_blank(),
axis.text=element_text(size=18, colour = "black"),
axis.title=element_text(size=24, face = "bold"),
axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"),
legend.text = element_text(size = 18),
plot.title = element_text(size = 26, face = "bold", vjust = 1),
panel.margin = unit(1.0, "lines"),
plot.margin = unit(c(0.5,  0.5, 0.5, 0.5), "lines"),
axis.line = element_line(colour = "black", size = 2),
axis.ticks = element_line(color = 'black', size = 3),
axis.ticks.length = unit(.25, 'cm')
)
theme_black = function(base_size = 12, base_family = "") {
theme_grey(base_size = base_size, base_family = base_family) %+replace%
theme(
# Specify axis options
axis.line = element_blank(),
axis.text.x = element_text(size = 12, color = "white", lineheight = 0.9),
axis.text.y = element_text(size = 12, color = "white", lineheight = 0.9),
axis.ticks = element_line(color = "white", size  =  0.2),
axis.title.x = element_text(size = 18, color = "white", margin = margin(0, 10, 0, 0)),
axis.title.y = element_text(size = 18, color = "white", angle = 90, margin = margin(0, 10, 0, 0)),
axis.ticks.length = unit(0.3, "lines"),
# Specify legend options
legend.background = element_rect(color = NA, fill = "black"),
legend.key = element_rect(color = "white",  fill = "black"),
legend.key.size = unit(1.2, "lines"),
legend.key.height = NULL,
legend.key.width = NULL,
legend.text = element_text(size = base_size*0.8, color = "white"),
legend.title = element_text(size = base_size*0.8, face = "bold", hjust = 0, color = "white"),
legend.position = "right",
legend.text.align = NULL,
legend.title.align = NULL,
legend.direction = "vertical",
legend.box = NULL,
# Specify panel options
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
panel.border = element_rect(fill = NA, color = "white"),
# Specify facetting options
strip.background = element_rect(fill = "grey30", color = "grey10"),
strip.text.x = element_text(size = base_size*0.8, color = "white"),
strip.text.y = element_text(size = base_size*0.8, color = "white",angle = -90),
# Specify plot options
plot.background = element_rect(color = "black", fill = "black"),
plot.title = element_text(size = base_size*1.2, color = "white"),
plot.margin = unit(rep(1, 4), "lines")
)
}
se = function(x) {return(sd(x, na.rm = T) / sqrt(sum(!is.na(x))))}
se.prop = function(x) {return(sqrt(mean(x, na.rm = T) * (1-mean(x, na.rm = T)) / sum(!is.na(x))))}
get.ci = function(x) {return(c(mean(x,na.rm = T) - 1.96*se(x), mean(x, na.rm = T), mean(x, na.rm = T) + 1.96*se(x)))}
get.ci.prop = function(x) {return(c(mean(x,na.rm = T) - 1.96*se.prop(x), mean(x, na.rm = T), mean(x, na.rm = T) + 1.96*se.prop(x)))}
print.ci = function(x) {
ci = signif(get.ci(x), 2)
return(paste0(ci[2], ' [', ci[1], ' - ', ci[3], ']'))
}
print.ci.prop = function(x) {
ci = signif(get.ci.prop(x), 2)
return(paste0(ci[2], ' [', ci[1], ' - ', ci[3], ']'))
}
as.string.vector = function(x) {
return(strsplit(x,',')[[1]])
}
as.numeric.vector = function(x) {
return(as.numeric(strsplit(gsub('\\[|\\]','',x),',')[[1]]))
}
as.string = function(x) {
return(paste(x, collapse = ','))
}
dodge <- position_dodge(width=0.9)
# for loading model fitting results
combine_lists <- function(directory) {
# Get a list of .RData files in the directory
files <- list.files(directory, pattern="^modeling_output_.*\\.rdata$", full.names=TRUE)
# Create an empty list to store the data
all_data <- list()
# Load the data from each file
for (i in 1:length(files)) {
load(paste0(directory, 'modeling_output_', i, '.rdata'))
all_data <- c(all_data, fitting_results_split_cur)
}
return(all_data)
}
print.stats = function(m, param, standardized = T) {
m.coef = summary(m)$coefficients[param,]
b = m.coef[1]
t = m.coef[4]
df = m.coef[3]
p = m.coef[5]
m.ci = suppressMessages(confint(m, param))
if (p >= .001) {
p.string = paste0(', p = ', signif(p,2))
} else {
p.string = paste0(', p < .001')
}
coef.char = ifelse(standardized, 'β', 'b')
paste0(coef.char, ' = ', signif(b,2),
' [', signif(m.ci[1], 2), ',', signif(m.ci[2], 2),
'], t(', signif(df, 2), ') = ', signif(t, 2), p.string)
}
print.stats.binom = function(m, param, standardized = T) {
m.coef = summary(m)$coefficients[param,]
b = m.coef[1]
t = m.coef[3]
p = m.coef[4]
m.ci = suppressMessages(confint(m, param))
if (p >= .001) {
p.string = paste0(', p = ', signif(p,2))
} else {
p.string = paste0(', p < .001')
}
coef.char = ifelse(standardized, 'β', 'b')
paste0(coef.char, ' = ', signif(b,2),
' [', signif(m.ci[1], 2), ',', signif(m.ci[2], 2),
'], z = ', signif(t, 2), p.string)
}
print.stats.lm = function(m, param, standardized = T) {
m.coef = summary(m)$coefficients[param,]
b = m.coef[1]
t = m.coef[3]
p = m.coef[4]
m.ci = suppressMessages(confint(m, param))
if (p >= .001) {
p.string = paste0(', p = ', signif(p,2))
} else {
p.string = paste0(', p < .001')
}
coef.char = ifelse(standardized, 'β', 'b')
paste0(coef.char, ' = ', signif(b,2), ' [', signif(m.ci[1], 2), ',', signif(m.ci[2], 2),
'], t = ', signif(t, 2), p.string)
}
options(digits = 2)
set.seed(12345)
# Set version -------------------------------------------------------------
## which version do we want?
versions = c('pilot1', 'pilot2', 'real1')
version = versions[3]
filepath = paste0(version, '/')
filepath_data = paste0(filepath, 'data/')
# Load data ---------------------------------------------------------------
numTrials = 10
# df.demo (short for "demographics") has all the subject-level information, i.e. one row per subject
df.demo.raw = read.csv(paste0(filepath_data, 'demo.csv'), stringsAsFactors = F)
# df.s1 has the data from stage 1 (where people make choices)
df.norms.raw = read.csv(paste0(filepath_data,'norms.csv'), stringsAsFactors = F)
# filter out anyone who didn't finish
subjlist.demo = unique(df.demo.raw$subject)
subjlist.norms = unique(df.norms.raw$subject)
subjlist = sort(Reduce(intersect, list(subjlist.demo, subjlist.norms)))
df.demo = df.demo.raw %>% filter(subject %in% subjlist) %>%
mutate(subject = factor(subject), subject.num = as.numeric(subject)) %>%
arrange(subject) %>%
rowwise() %>%
mutate(total_time_real = total_time / 60000,
instructions_times_list = list(as.numeric.vector(instructions_times) / 1000),
stamp = parse_date_time(stamp, c('ymd HMS', 'mdy HMS', 'mdy HM'))) %>%
ungroup()
for (i in 1:nrow(df.demo)) {
df.demo$instruction_times_median[i] = median(df.demo$instructions_times_list[i][[1]])
df.demo$instruction_times_sd[i] = sd(df.demo$instructions_times_list[i][[1]])
}
df.norms = df.norms.raw %>% filter(subject %in% subjlist) %>%
arrange(subject, trial) %>%
mutate(subject = factor(subject), subject.num = as.numeric(subject))
# Filter ------------------------------------------------------------------
to.exclude = df.demo %>%
filter(attention_check2_pass == 'Fail' | attention_check3_pass == 'Fail') %>%
pull(subject)
df.demo.filt = df.demo %>% filter(!(subject %in% to.exclude))
df.norms.filt = df.norms %>% filter(!(subject %in% to.exclude))
nrow(df.demo.filt)
# Descriptives
ggplot(df.norms.filt, aes(x = age)) +
geom_histogram()
ggplot(df.norms.filt, aes(x = dominance)) +
geom_histogram()
ggplot(df.norms.filt, aes(x = trustworthiness)) +
geom_histogram()
ggplot(df.norms.filt, aes(x = attractiveness)) +
geom_histogram()
View(df.norms.filt)
df.norms.filt %>%
group_by(face_id) %>%
summarize(age.m = mean(age),
age.se = se(age),
dominance.m = mean(dominance),
dominance.se = se(dominance),
trustworthiness.m = mean(trustworthiness),
trustworthiness.se = se(trustworthiness),
attractiveness.m = mean(attractiveness),
attractiveness.se = se(attractiveness))
df.byface = df.norms.filt %>%
group_by(face_id) %>%
summarize(age.m = mean(age),
age.se = se(age),
dominance.m = mean(dominance),
dominance.se = se(dominance),
trustworthiness.m = mean(trustworthiness),
trustworthiness.se = se(trustworthiness),
attractiveness.m = mean(attractiveness),
attractiveness.se = se(attractiveness))
View(df.byface)
df.faces = read.csv('face-norms-expanded.csv')
df.faces
df.faces
View(df.faces)
df.demo$feedback
df.demo$total_time_real
median(df.demo$total_time_real)
rm(list=ls())
load("/Users/am9578/My Drive/Psychology/Projects/menagerie/noa_git/menagerie/analysis/osf/power_analysis/power_analysis_prereq.rdata")
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'tidyverse', 'this.path', 'brms', 'bayestestR', 'rstan', 'posterior', 'parallel', 'doParallel')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
task_list = c(unique(combined_data_introspection_experience$task_name), paste0("newtask_",1:5))
num_tasks = length(task_list)
original_analysis = T
observer_analysis = F
observer_coefficient_mean = -0.15
observer_coefficient_sd = 0.10
sigma_est <- mean(as_draws_df(combined_analysis_introspection_continuous)$sigma)
sample_sizes = c(400, 600)
num_runs_per = 100
numCores = 32
numCores = 4
registerDoParallel(numCores)
results_all = vector(mode = 'list', length = length(sample_sizes))
results_all_obs = vector(mode = 'list', length = length(sample_sizes))
for (i in 1:length(sample_sizes)) {
sample_size = sample_sizes[i]
new_data_template = combined_data_introspection_experience %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(combined_data_introspection_experience, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_")) %>%
group_by(subject) %>% # fill in missing tasks
group_modify(~ fill_missing_tasks(.x, combined_data_introspection_experience)) %>%
ungroup() %>%
select(!c(introspect_rating, instance, study))
post_draws = posterior_predict(combined_analysis_introspection_continuous,
newdata = new_data_template,
ndraws = num_runs_per,
allow_new_levels = T)
new_data_template_obs = rbind(new_data_template %>% mutate(participant_type = 0, actor_id = subject),
new_data_template %>% mutate(actor_id = subject, subject = paste0(subject, "_obs"), participant_type = 1)) %>%
mutate(effect_size_range = scale(effect_size_range)) %>%
group_by(subject) %>%
mutate(observer_coefficient = rnorm(1, mean = observer_coefficient_mean, sd = observer_coefficient_sd)) %>%
ungroup()
post_draws_obs_orig <- posterior_predict(combined_analysis_introspection_continuous,
newdata = new_data_template_obs,
ndraws = num_runs_per,
allow_new_levels = T)
interaction_term <- new_data_template_obs$observer_coefficient * new_data_template_obs$effect_size_range * new_data_template_obs$participant_type
post_draws_obs_new <- post_draws_obs_orig + matrix(rep(interaction_term, times = nrow(post_draws_obs_orig)), nrow = nrow(post_draws_obs_orig), byrow = T)
post_draws_obs_new <- post_draws_obs_new + matrix(rnorm(length(post_draws_obs_new), mean = 0, sd = sigma_est), nrow = nrow(post_draws_obs_new), ncol = ncol(post_draws_obs_new))
if (original_analysis) {
results = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
new_data = new_data_template
new_data$introspect_rating = t(post_draws)[,j]
power_analysis = brm(introspect_rating ~ effect_size_range + (effect_size_range || subject) + (effect_size_range || task_name),
new_data %>% mutate(introspect_rating = scale(introspect_rating),
effect_size_range = scale(effect_size_range)),
prior = default_priors,
save_pars = save_pars(group = F),
control = list(adapt_delta = 0.95))
power_analysis_hdi = bayestestR::hdi(power_analysis)
coef_estimate = summary(power_analysis)$fixed$Estimate[2]
hdi_high = power_analysis_hdi$CI_high[2]
hdi_low = power_analysis_hdi$CI_low[2]
list(coef_estimate, hdi_low, hdi_high)
}
results_df <- as.data.frame(results)
results_df = data.frame(lapply(results_df, unlist))
colnames(results_df) <- c("coef_estimate", "hdi_low", "hdi_high")
rownames(results_df) <- paste0("Run_", 1:num_runs_per)
results_all[[i]] = results_df %>%
mutate(hdi_width = hdi_high - hdi_low,
hdi_significant = hdi_low > .05)
}
if (observer_analysis) {
results_obs = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
new_data_obs = new_data_template_obs
new_data_obs$introspect_rating = t(post_draws_obs_new)[,j]
power_analysis = brm(introspect_rating ~ effect_size_range * participant_type +
(effect_size_range * participant_type || actor_id) +
(1 | actor_id:subject) +
(effect_size_range || task_name),
new_data_obs %>% mutate(introspect_rating = scale(introspect_rating),
effect_size_range = scale(effect_size_range)),
prior = default_priors,
save_pars = save_pars(group = F))
power_analysis_hdi = bayestestR::hdi(power_analysis)
coef_estimate = summary(power_analysis)$fixed$Estimate[4]
hdi_high = power_analysis_hdi$CI_high[4]
hdi_low = power_analysis_hdi$CI_low[4]
list(coef_estimate, hdi_low, hdi_high)
}
results_obs_df <- as.data.frame(results_obs)
results_obs_df = data.frame(lapply(results_obs_df, unlist))
colnames(results_obs_df) <- c("coef_estimate", "hdi_low", "hdi_high")
rownames(results_obs_df) <- paste0("Run_", 1:num_runs_per)
results_all_obs[[i]] = results_obs_df %>%
mutate(hdi_width = hdi_high - hdi_low,
hdi_significant = hdi_high < -.05)
}
}
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'tidyverse', 'this.path', 'brms', 'bayestestR', 'rstan', 'posterior', 'parallel', 'doParallel')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
default_priors <- set_prior("normal(0,1)", class = 'b')
fill_missing_tasks <- function(df, full_data) {
completed_tasks <- unique(df$task_name)
missing_tasks <- setdiff(task_list, completed_tasks)
if (length(missing_tasks) > 0) {
for (task in missing_tasks) {
task_data <- full_data %>% filter(task_name == task)
if (nrow(task_data) > 0) {
new_row <- task_data %>% slice_sample(n = 1)
} else {
# If the task doesn't exist, sample a random row and assign the missing task name
new_row <- full_data %>% slice_sample(n = 1)
new_row$task_name <- task
}
new_row$subject <- unique(df$subject) # Assign to the sampled subject
df <- bind_rows(df, new_row)
}
}
return(df)
}
## run power analysis from existing data
load('power_analysis_prereq.rdata')
task_list = c(unique(combined_data_introspection_experience$task_name), paste0("newtask_",1:5))
num_tasks = length(task_list)
original_analysis = T
observer_analysis = F
observer_coefficient_mean = -0.15
observer_coefficient_sd = 0.10
sigma_est <- mean(as_draws_df(combined_analysis_introspection_continuous)$sigma)
sample_sizes = c(400, 600)
num_runs_per = 100
numCores = 4
registerDoParallel(numCores)
results_all = vector(mode = 'list', length = length(sample_sizes))
results_all_obs = vector(mode = 'list', length = length(sample_sizes))
for (i in 1:length(sample_sizes)) {
sample_size = sample_sizes[i]
new_data_template = combined_data_introspection_experience %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(combined_data_introspection_experience, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_")) %>%
group_by(subject) %>% # fill in missing tasks
group_modify(~ fill_missing_tasks(.x, combined_data_introspection_experience)) %>%
ungroup() %>%
select(!c(introspect_rating, instance, study))
post_draws = posterior_predict(combined_analysis_introspection_continuous,
newdata = new_data_template,
ndraws = num_runs_per,
allow_new_levels = T)
new_data_template_obs = rbind(new_data_template %>% mutate(participant_type = 0, actor_id = subject),
new_data_template %>% mutate(actor_id = subject, subject = paste0(subject, "_obs"), participant_type = 1)) %>%
mutate(effect_size_range = scale(effect_size_range)) %>%
group_by(subject) %>%
mutate(observer_coefficient = rnorm(1, mean = observer_coefficient_mean, sd = observer_coefficient_sd)) %>%
ungroup()
post_draws_obs_orig <- posterior_predict(combined_analysis_introspection_continuous,
newdata = new_data_template_obs,
ndraws = num_runs_per,
allow_new_levels = T)
interaction_term <- new_data_template_obs$observer_coefficient * new_data_template_obs$effect_size_range * new_data_template_obs$participant_type
post_draws_obs_new <- post_draws_obs_orig + matrix(rep(interaction_term, times = nrow(post_draws_obs_orig)), nrow = nrow(post_draws_obs_orig), byrow = T)
post_draws_obs_new <- post_draws_obs_new + matrix(rnorm(length(post_draws_obs_new), mean = 0, sd = sigma_est), nrow = nrow(post_draws_obs_new), ncol = ncol(post_draws_obs_new))
if (original_analysis) {
results = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
new_data = new_data_template
new_data$introspect_rating = t(post_draws)[,j]
power_analysis = brm(introspect_rating ~ effect_size_range + (effect_size_range || subject) + (effect_size_range || task_name),
new_data %>% mutate(introspect_rating = scale(introspect_rating),
effect_size_range = scale(effect_size_range)),
prior = default_priors,
save_pars = save_pars(group = F),
control = list(adapt_delta = 0.95))
power_analysis_hdi = bayestestR::hdi(power_analysis)
coef_estimate = summary(power_analysis)$fixed$Estimate[2]
hdi_high = power_analysis_hdi$CI_high[2]
hdi_low = power_analysis_hdi$CI_low[2]
list(coef_estimate, hdi_low, hdi_high)
}
results_df <- as.data.frame(results)
results_df = data.frame(lapply(results_df, unlist))
colnames(results_df) <- c("coef_estimate", "hdi_low", "hdi_high")
rownames(results_df) <- paste0("Run_", 1:num_runs_per)
results_all[[i]] = results_df %>%
mutate(hdi_width = hdi_high - hdi_low,
hdi_significant = hdi_low > .05)
}
if (observer_analysis) {
results_obs = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
new_data_obs = new_data_template_obs
new_data_obs$introspect_rating = t(post_draws_obs_new)[,j]
power_analysis = brm(introspect_rating ~ effect_size_range * participant_type +
(effect_size_range * participant_type || actor_id) +
(1 | actor_id:subject) +
(effect_size_range || task_name),
new_data_obs %>% mutate(introspect_rating = scale(introspect_rating),
effect_size_range = scale(effect_size_range)),
prior = default_priors,
save_pars = save_pars(group = F))
power_analysis_hdi = bayestestR::hdi(power_analysis)
coef_estimate = summary(power_analysis)$fixed$Estimate[4]
hdi_high = power_analysis_hdi$CI_high[4]
hdi_low = power_analysis_hdi$CI_low[4]
list(coef_estimate, hdi_low, hdi_high)
}
results_obs_df <- as.data.frame(results_obs)
results_obs_df = data.frame(lapply(results_obs_df, unlist))
colnames(results_obs_df) <- c("coef_estimate", "hdi_low", "hdi_high")
rownames(results_obs_df) <- paste0("Run_", 1:num_runs_per)
results_all_obs[[i]] = results_obs_df %>%
mutate(hdi_width = hdi_high - hdi_low,
hdi_significant = hdi_high < -.05)
}
}
warnings()
install.packages('brms')
