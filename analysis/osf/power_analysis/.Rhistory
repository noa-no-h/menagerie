WF-006
WF-007
WF-008
WF-009
WF-010
WF-011
WF-012
WF-013
WF-014
WF-015
WF-016
WF-017
WF-018
WF-019
WF-020
WF-021
WF-022
WF-023
WF-024
WF-025
WF-026
WF-027
WF-028
WF-029
WF-030
WF-031
WF-033
WF-034
WF-035
WF-036
WF-037
WF-038
WF-039
WF-200
WF-201
WF-202
WF-203
WF-204
WF-205
WF-206
WF-207
WF-208
WF-209
WF-210
WF-211
WF-212
WF-213
WF-214
WF-215
WF-216
WF-217
WF-218
WF-219
WF-220
WF-221
WF-222
WF-223
WF-224
WF-225
WF-226
WF-227
WF-228
WF-229
WF-230
WF-231
WF-232
WF-233
WF-234
WF-235
WF-236
WF-237
WF-238
WF-239
WF-240
WF-241
WF-242
WF-243
WF-244
WF-245
WF-246
WF-247
WF-248
WF-249
WF-250
WF-251
WF-252
WM-001
WM-002
WM-003
WM-004
WM-006
WM-009
WM-010
WM-011
WM-012
WM-013
WM-014
WM-015
WM-016
WM-017
WM-018
WM-019
WM-020
WM-021
WM-022
WM-023
WM-024
WM-025
WM-026
WM-028
WM-029
WM-031
WM-032
WM-033
WM-034
WM-035
WM-036
WM-037
WM-038
WM-039
WM-040
WM-041
WM-200
WM-201
WM-202
WM-203
WM-204
WM-205
WM-206
WM-207
WM-208
WM-209
WM-210
WM-211
WM-212
WM-213
WM-214
WM-215
WM-216
WM-217
WM-218
WM-219
WM-220
WM-221
WM-222
WM-223
WM-224
WM-225
WM-227
WM-228
WM-229
WM-230
WM-231
WM-232
WM-233
WM-234
WM-235
WM-236
WM-237
WM-238
WM-239
WM-240
WM-241
WM-242
WM-243
WM-244
WM-245
WM-247
WM-248
WM-249
WM-250
WM-251
WM-252
WM-253
WM-254
WM-255
WM-256
WM-257
WM-258"
csv_list <- gsub("\n", ",", ids)
csv_list
load("/Users/am9578/My Drive/Psychology/Projects/ma_choice_okcupid/git/experiments/real2/analysis_output.rdata")
# for NIH reporting
nrow(df.demo)
prop.table(table(df.demo.filt$race))
table(df.demo$race)
sum(df.demo$race != 'White')
sum(df.demo$race != ['White'])
sum(df.demo$race != '[White]')
df.demo$race
sum(df.demo$race != '[\"White\"]')
sum(grepl("Hispanic", df.demo$race, ignore.case = TRUE))
load("/Users/am9578/My Drive/Psychology/Projects/ma_choice/git3/data-analysis/home-fixed/analysis_output.rdata")
table(df.demo.filt$actual.model.fac)
87+40
60+15+26+9
110 / (110 + 127)
rm(list=ls())
load("/Users/am9578/My Drive/Psychology/Projects/ma_choice/git3/data-analysis/movie/analysis_output.rdata")
table(df.demo.filt$actual.model.fac)
30 / (147 + 30 + 23 + 54)
30 / (147 + 30 + 23 + 5)
load("/Users/am9578/My Drive/Psychology/Projects/ma_choice/git3_pristine_osf/data-analysis/expert-prediction/analysis_output.rdata")
nrow(df)
table(df$Role.fac)
df$Role.fac
df[66]
df[66,]
# Load necessary library
set.seed(42)  # For reproducibility
# Simulate data for 100 choices
data <- data.frame(
choice_id = 1:100,
# Calendar A attributes
width_A = runif(100, 8, 24),
height_A = runif(100, 10, 36),
writing_space_size_A = runif(100, 2, 16),
number_of_images_A = sample(12:24, 100, replace = TRUE),
paper_thickness_A = runif(100, 100, 250),
# Calendar B attributes
width_B = runif(100, 8, 24),
height_B = runif(100, 10, 36),
writing_space_size_B = runif(100, 2, 16),
number_of_images_B = sample(12:24, 100, replace = TRUE),
paper_thickness_B = runif(100, 100, 250),
# Simulated choice outcome: 1 if Calendar A is chosen, 0 if Calendar B is chosen
choice = sample(0:1, 100, replace = TRUE)
)
# View the first few rows of the simulated data
head(data)
data.scaled = data %>%
mutate(width_diff = width_A - width_B,
height_diff = height_A - height_B,
number_of_images_diff = number_of_images_A - number_of_images_B,
writing_space_size_diff = writing_space_size_A - writing_space_size_B,
paper_thickness_diff = paper_thickness_A - paper_thickness_B)
require(tidyverse)
data.scaled = data %>%
mutate(width_diff = width_A - width_B,
height_diff = height_A - height_B,
number_of_images_diff = number_of_images_A - number_of_images_B,
writing_space_size_diff = writing_space_size_A - writing_space_size_B,
paper_thickness_diff = paper_thickness_A - paper_thickness_B)
View(data.scaled)
range(c(1,2,3,4), c(0,1))
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
data.scaled = data %>%
mutate(width_diff = range01(width_A - width_B),
height_diff = range01(height_A - height_B),
number_of_images_diff = range01(number_of_images_A - number_of_images_B),
writing_space_size_diff = range01(writing_space_size_A - writing_space_size_B),
paper_thickness_diff = range01(paper_thickness_A - paper_thickness_B))
View(data.scaled)
test = glm(choice ~ width_diff + height_diff + number_of_images_diff + writing_space_size_diff + paper_thickness_diff)
test = glm(choice ~ width_diff + height_diff + number_of_images_diff + writing_space_size_diff + paper_thickness_diff,
data.scaled)
test = glm(choice ~ width_diff + height_diff + number_of_images_diff + writing_space_size_diff + paper_thickness_diff,
data.scaled,
family = 'binomial')
test
summary(test)
test$coefficients
exp(test$coefficients)
rescale_to_sum_one <- function(vec) {
vec / sum(vec)
}
rescale_to_sum_one(test$coefficients)
rescale_to_sum_one(exp(test$coefficients))
# Calculate sample size
result = power.t.test(delta = 0.4, sd = 1, sig.level = 0.05, power = 0.80, type = "two.sample", alternative = 'one.sided')
result$n * 4/3 * 2
# Calculate sample size
result = power.t.test(delta = 0.2, sd = 1, sig.level = 0.05, power = 0.80, type = "two.sample", alternative = 'one.sided')
result$n * 4/3 * 2
# Calculate sample size
result = power.t.test(delta = 0.25, sd = 1, sig.level = 0.05, power = 0.80, type = "two.sample", alternative = 'one.sided')
result$n * 4/3 * 2
load("/Users/am9578/My Drive/Psychology/Projects/ma_choice/git3_pristine_osf/data-analysis/home-fixed/analysis_output.rdata")
summary(lm(scale(weight.accuracy.averaged) ~ scale(actual.inv.temp), data = df.demo.filt))
summary(lm(scale(weight.accuracy.averaged) ~ scale(actual.model.loo.readable), data = df.demo.filt))
summary(lm(scale(weight.accuracy.actual) ~ scale(actual.model.loo.readable), data = df.demo.filt))
load("/Users/am9578/My Drive/Psychology/Projects/menagerie/noa_git/menagerie/analysis/osf/power_analysis/power_analysis_results.rdata")
results_all_obs
# analyze
lapply(results_all_obs, colMeans)
i = 1
sample_size = sample_sizes[i]
new_data_template = combined_data_introspection_experience %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(combined_data_introspection_experience, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_")) %>%
group_by(subject) %>% # fill in missing tasks
group_modify(~ fill_missing_tasks(.x, combined_data_introspection_experience)) %>%
ungroup() %>%
select(!c(introspect_rating, instance, study))
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'tidyverse', 'this.path', 'brms', 'bayestestR', 'rstan', 'posterior', 'parallel', 'doParallel')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
default_priors <- set_prior("normal(0,1)", class = 'b')
fill_missing_tasks <- function(df, full_data) {
completed_tasks <- unique(df$task_name)
missing_tasks <- setdiff(task_list, completed_tasks)
if (length(missing_tasks) > 0) {
for (task in missing_tasks) {
task_data <- full_data %>% filter(task_name == task)
if (nrow(task_data) > 0) {
new_row <- task_data %>% slice_sample(n = 1)
} else {
# If the task doesn't exist, sample a random row and assign the missing task name
new_row <- full_data %>% slice_sample(n = 1)
new_row$task_name <- task
}
new_row$subject <- unique(df$subject) # Assign to the sampled subject
df <- bind_rows(df, new_row)
}
}
return(df)
}
sample_size = sample_sizes[i]
new_data_template = combined_data_introspection_experience %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(combined_data_introspection_experience, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_")) %>%
group_by(subject) %>% # fill in missing tasks
group_modify(~ fill_missing_tasks(.x, combined_data_introspection_experience)) %>%
ungroup() %>%
select(!c(introspect_rating, instance, study))
load("/Users/am9578/My Drive/Psychology/Projects/menagerie/noa_git/menagerie/analysis/osf/power_analysis/power_analysis_prereq.rdata")
new_data_template = combined_data_introspection_experience %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(combined_data_introspection_experience, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_")) %>%
group_by(subject) %>% # fill in missing tasks
group_modify(~ fill_missing_tasks(.x, combined_data_introspection_experience)) %>%
ungroup() %>%
select(!c(introspect_rating, instance, study))
task_list = c(unique(combined_data_introspection_experience$task_name), paste0("newtask_",1:5))
num_tasks = length(task_list)
original_analysis = F
observer_analysis = T
observer_coefficient = -0.15
sigma_est <- mean(as_draws_df(combined_analysis_introspection_continuous)$sigma)
sample_sizes = c(300,400,500)
num_runs_per = 100
numCores = 32
registerDoParallel(numCores)
results_all = vector(mode = 'list', length = length(sample_sizes))
results_all_obs = vector(mode = 'list', length = length(sample_sizes))
sample_size = sample_sizes[i]
new_data_template = combined_data_introspection_experience %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(combined_data_introspection_experience, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_")) %>%
group_by(subject) %>% # fill in missing tasks
group_modify(~ fill_missing_tasks(.x, combined_data_introspection_experience)) %>%
ungroup() %>%
select(!c(introspect_rating, instance, study))
post_draws = posterior_predict(combined_analysis_introspection_continuous,
newdata = new_data_template,
ndraws = num_runs_per,
allow_new_levels = T)
new_data_template_obs = rbind(new_data_template %>% mutate(participant_type = 0, actor_id = subject),
new_data_template %>% mutate(actor_id = subject, subject = paste0(subject, "_obs"), participant_type = 1)) %>%
mutate(effect_size_range = scale(effect_size_range))
post_draws_obs_orig <- posterior_predict(combined_analysis_introspection_continuous,
newdata = new_data_template_obs,
ndraws = num_runs_per,
allow_new_levels = T)
size(new_data_template_obs$effect_size_range)
dim(new_data_template_obs$effect_size_range)
View(new_data_template_obs)
interaction_term <- observer_coefficient * new_data_template_obs$effect_size_range * new_data_template_obs$participant_type
dim(interaction_term)
interaction_term
matrix(rep(interaction_term, times = nrow(post_draws_obs_orig)), nrow = nrow(post_draws_obs_orig), byrow = T)
dim(post_draws_obs_orig)
rep(c(23423,23423,45235623), times = 5)
observer_coefficient
new_data_template_obs$subject
LETTERS
new_data_template_obs %>% group_by(subject) %>% mutate(observer_coefficient = first(rnorm(1))) %>% ungroup()
test = new_data_template_obs %>% group_by(subject) %>% mutate(observer_coefficient = first(rnorm(1))) %>% ungroup()
test$observer_coefficient
test = new_data_template_obs %>% group_by(subject) %>% mutate(observer_coefficient = rnorm(1)) %>% ungroup()
test$observer_coefficient
View(new_data_template_obs)
summary(combined_analysis_introspection_continuous)
#
# combined_data_introspection_experience = all_data_introspection_experience_pilot1 %>%
#   mutate(introspect_rating = (introspect_rating - 50) / 40,
#          study = 'pilot1') %>%
#   rbind(all_data_introspection_experience_pilot2 %>% mutate(introspect_rating = introspect_rating / 50, study = 'pilot2')) %>%
#   mutate(introspect_rating = scale(introspect_rating),
#          effect_size_range = scale(effect_size_range))
#
# ## run combined analyses
#
combined_analysis_introspection_continuous = brm(introspect_rating ~ effect_size_range + (effect_size_range || subject) + (effect_size_range || task_name),
combined_data_introspection_experience %>% mutate(introspect_rating = scale(introspect_rating),
effect_size_range = scale(effect_size_range)),
prior = default_priors,
#save_pars = save_pars(group = F),
cores = 4,
control = list(adapt_delta = 0.95))
summary(combined_analysis_introspection_continuous)
observer_coefficient_mean = -0.15
observer_coefficient_sd = 0.10
new_data_template_obs = rbind(new_data_template %>% mutate(participant_type = 0, actor_id = subject),
new_data_template %>% mutate(actor_id = subject, subject = paste0(subject, "_obs"), participant_type = 1)) %>%
mutate(effect_size_range = scale(effect_size_range)) %>%
group_by(subject) %>%
mutate(observer_coefficient = first(rnorm(observer_coefficient_mean, observer_coefficient_sd))) %>%
ungroup()
new_data_template_obs = rbind(new_data_template %>% mutate(participant_type = 0, actor_id = subject),
new_data_template %>% mutate(actor_id = subject, subject = paste0(subject, "_obs"), participant_type = 1)) %>%
mutate(effect_size_range = scale(effect_size_range)) %>%
group_by(subject) %>%
mutate(observer_coefficient = first(rnorm(1, mean = observer_coefficient_mean, sd = observer_coefficient_sd))) %>%
ungroup()
new_data_template_obs$observer_coefficient
new_data_template_obs = rbind(new_data_template %>% mutate(participant_type = 0, actor_id = subject),
new_data_template %>% mutate(actor_id = subject, subject = paste0(subject, "_obs"), participant_type = 1)) %>%
mutate(effect_size_range = scale(effect_size_range)) %>%
group_by(subject) %>%
mutate(observer_coefficient = rnorm(1, mean = observer_coefficient_mean, sd = observer_coefficient_sd)) %>%
ungroup()
new_data_template_obs$observer_coefficient
post_draws_obs_orig <- posterior_predict(combined_analysis_introspection_continuous,
newdata = new_data_template_obs,
ndraws = num_runs_per,
allow_new_levels = T)
interaction_term <- new_data_template_obs$observer_coefficient * new_data_template_obs$effect_size_range * new_data_template_obs$participant_type
post_draws_obs_new <- post_draws_obs_orig + matrix(rep(interaction_term, times = nrow(post_draws_obs_orig)), nrow = nrow(post_draws_obs_orig), byrow = T)
post_draws_obs_new <- post_draws_obs_new + matrix(rnorm(length(post_draws_obs_new), mean = 0, sd = sigma_est), nrow = nrow(post_draws_obs_new), ncol = ncol(post_draws_obs_new))
new_data_obs = new_data_template_obs
j = 1
new_data_obs$introspect_rating = t(post_draws_obs_new)[,j]
power_analysis = brm(introspect_rating ~ effect_size_range * participant_type +
#(1 | actor_id) +
(effect_size_range * participant_type | actor_id:subject) +
(1 | task_name),
new_data_obs %>% mutate(introspect_rating = scale(introspect_rating),
effect_size_range = scale(effect_size_range)),
prior = default_priors,
save_pars = save_pars(group = F))
summary(power_analysis)
power_analysis = brm(introspect_rating ~ effect_size_range * participant_type +
(effect_size_range * participant_type || actor_id) +
(effect_size_range || actor_id:subject) +
(effect_size_range || task_name),
new_data_obs %>% mutate(introspect_rating = scale(introspect_rating),
effect_size_range = scale(effect_size_range)),
prior = default_priors,
save_pars = save_pars(group = F))
summary(power_analysis)
power_analysis = brm(introspect_rating ~ effect_size_range * participant_type +
(effect_size_range * participant_type || actor_id) +
(1 | actor_id:subject) +
(effect_size_range || task_name),
new_data_obs %>% mutate(introspect_rating = scale(introspect_rating),
effect_size_range = scale(effect_size_range)),
prior = default_priors,
save_pars = save_pars(group = F))
summary(power_analysis)
summarize_draws(power_analysis)
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'tidyverse', 'this.path', 'brms', 'bayestestR', 'rstan', 'posterior', 'parallel', 'doParallel')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
default_priors <- set_prior("normal(0,1)", class = 'b')
load("/Users/am9578/My Drive/Psychology/Projects/menagerie/noa_git/menagerie/analysis/osf/power_analysis/power_analysis_results.rdata")
observer_coefficient_mean
observer_coefficient_sd
# analyze
lapply(results_all_obs, colMeans)
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'tidyverse', 'this.path', 'brms', 'bayestestR', 'rstan', 'posterior', 'parallel', 'doParallel')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
default_priors <- set_prior("normal(0,1)", class = 'b')
load("/Users/am9578/My Drive/Psychology/Projects/menagerie/noa_git/menagerie/analysis/osf/power_analysis/power_analysis_results.rdata")
# analyze
lapply(results_all_obs, colMeans)
