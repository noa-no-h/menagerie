<<<<<<< Updated upstream
=======
coin_outputs = c("H","T")
N=10000
tosses=sample(coin_outputs, size=N, prob = c(0.2, 0.8), replace=TRUE)
Hn = cumsum(tosses=="H")
simu = data.frame(n = 1:N, Hn1 = Hn)
ggplot(data=simu, aes(x=n, y= Hn1/n-0.2))+
geom_line()
coin_outputs = c("H","T")
N=10000
tosses=sample(coin_outputs, size=N, prob = c(0.2, 0.8), replace=TRUE)
Hn = cumsum(tosses=="H")
simu = data.frame(n = 1:N, Hn1 = Hn)
ggplot(data=simu, aes(x=n, y= Hn1-0.2*n))+
geom_line()
coin_outputs = c("H","T")
N=10000
tosses=sample(coin_outputs, size=N, prob = c(0.2, 0.8), replace=TRUE)
Hn = cumsum(tosses=="H")
simu = data.frame(n = 1:N, Hn1 = Hn)
ggplot(data=simu, aes(x=n, y= Hn1/n-0.2))+
geom_line()
knitr::opts_chunk$set(echo = TRUE)
load("ames.RData")
download.file("http://www.openintro.org/stat/data/ames.RData", destfile = "ames.RData")
load("ames.RData")
area = ames$Gr.Liv.Area
price = ames$SalePrice
favstats(area)
library(ggplot2)
favstats(area)
library(mosaic)
favstats(area)
histogram(area)
histogram(area, fit='normal')
knitr::opts_chunk$set(echo = TRUE)
histogram(price, fit='normal')
histogram(price, fit='normal')
mean(price)
sd(price)
mean(sample(price, 25))
sample_means25 = do(5000) * mean(sample(price, 25))
sample_means25 = do(5000) * mean(sample(price, 25))
histogram(sample_means25)
sample_means25 = do(5000) * mean(sample(price, 25))
histogram(sample_means25$mean)
sample_means4 = do(5000) * mean(sample(price, 4))
histogram(sample_means4$mean)
sample_means100 = do(5000) * mean(sample(price, 1000))
histogram(sample_means100$mean)
median(sample_means25$mean)
median(sample_means4$mean)
median(sample_means100$mean)
mean(sample_means100$mean)
mean(sample_means4$mean)
mean(sample_means25$mean)
sd(sample_means25$mean)
sd(sample_means100$mean)
sd(sample_means4$mean)
```{r}
sd(sample_means100$mean)
sample_means100 = do(5000) * mean(sample(price, 1000))
histogram(sample_means100$mean)
sample_means4 = do(5000) * mean(sample(price, 4))
histogram(sample_means4$mean)
sample_means25 = do(5000) * mean(sample(price, 25))
histogram(sample_means25$mean)
knitr::opts_chunk$set(echo = TRUE)
rnorm(60, 10, 2.89)
sd(sample_means100$mean)
mean(sample_means4$mean)
mean(sample_means25$mean)
mean(sample_means100$mean)
sd(sample_means4$mean)
sd(sample_means25$mean)
sd(sample_means100$mean)
mean(sample_means100$mean)
sum(dbinom(8:12, size=60, p=1/6))
i) table(sample_means100 < 170)
knitr::opts_chunk$set(echo = TRUE)
table(sample_means100 < 170)
table(sample_means100 < 170)
knitr::opts_chunk$set(echo = TRUE)
download.file("http://www.openintro.org/stat/data/ames.RData", destfile = "ames.RData")
load("ames.RData")
area = ames$Gr.Liv.Area
price = ames$SalePrice
library(mosaic)
favstats(price)
histogram(price, fit='normal')
mean(price)
sd(price)
mean(sample(price, 25))
sample_means25 = do(5000) * mean(sample(price, 25))
histogram(sample_means25$mean)
sample_means4 = do(5000) * mean(sample(price, 4))
histogram(sample_means4$mean)
sample_means100 = do(5000) * mean(sample(price, 1000))
histogram(sample_means100$mean)
mean(sample_means25$mean)
mean(sample_means4$mean)
mean(sample_means100$mean)
sd(sample_means25$mean)
sd(sample_means4$mean)
sd(sample_means100$mean)
table(sample_means100$mean < 170)
table(sample_means100 < 170)
(130000-180796.1)/(79886.69/2)
pnorm(-1.27)
(190000-180796.1)/(79886.69/2)
pnorm(-1.27)
pnorm(0.2304239)
1-0.5911188
1-0.1020423-0.4088812
table(sample_means4 < 190000 & sample_means4 > 130000)
table(sample_means4 < 190000 & sample_means4 > 130000)/5000
knitr::opts_chunk$set(echo = TRUE)
weight <- c(1.7, 11.7, -1.4, 0.7, 6.1, -0.8, -0.1, 1.1, 2.4, -0.7, -4.0, 12.6, -3.5, 20.9,
1.9, 14.9, -9.3, 3.9, 3.5, 2.1, 0.1, 17.1, 1.4, 15.4, -7.6, -0.3, -0.7,1.6, -3.7)
mean(weight)
sd(weight)
3/(7.32/sqrt(29))
library(mosaic)
download.file("http://www.openintro.org/stat/data/bdims.RData", destfile = "bdims.RData")
load("bdims.RData")
library(mosaic)
download.file("http://www.openintro.org/stat/data/bdims.RData", destfile = "bdims.RData")
load("bdims.RData")
library(mosaic)
mdims = subset(bdims, sex == 1)
fdims = subset(bdims, sex == 0)
population = fdims$hgt
mu = mean(population); mu
mu = mean(population); mu
sigma = sd(population); sigma
histogram(population, fit="normal", nint=15, xlab="Women's height (cm)")
histogram(population, fit="normal", nint=15, xlab="Women's height (cm)")
histogram(population, fit="normal", nint=15, xlab="Women's height (cm)")
histogram(population, fit="normal", nint=15, xlab="Women's height (cm)")
samp = do(100) * favstats(sample(population, size = 5))
samp = do(100) * favstats(sample(population, size = 5))
head(samp)
head(samp)
panel.ci = function (x, y, mu, data2, ...) {
panel.xyplot(x, y, ...)
good = subset(data2, upper > mu & lower < mu)
bad = subset(data2, upper < mu | lower > mu)
with(good, panel.arrows(lower, .index, upper, .index, angle=90, length = 0.05, ends="both"))
with(bad, panel.arrows(lower, .index, upper, .index, angle=90, length = 0.05, ends="both", col="red", lwd=3))
panel.abline(v=mu, lty=2)
}
plot_ci = function (df, mu, ...) {
space = 0.1 * (max(df$lower) - min(df$upper))
xyplot(.index ~ mean, data=df, data2 = df, panel=panel.ci, mu = mu, xlim = c(min(df$lower) - space, max(df$upper) + space), ylab = NULL)
}
plot_ci(samp, mu = mean(population))
Endotoxin =
c(708.23, 911.60, 976.81, 1316.63, 262.74, 9772.08, 370.76, 229.16, 2570.51,
891.19, 3163.20, 1777.65, 1288.57, 436.23, 2631.63, 1173.52, 911.67, 7942.42,
740.32, 356.92, 1175.48, 1480.55, 2754.61, 575.62, 573.89, 468.26, 1000.71,
364.22, 1025.26, 1022.04, 645.41, 363.57, 977.47, 1022.75, 1860.63, 371.13,
174.73, 399.68, 1479.77, 2882.96, 601.99, 1697.32, 2291.00, 646.49, 1176.27,
1995.43, 955.54, 1480.05, 456.71, 1174.70, 5494.22)
library(mosaic)
bwplot(Endotoxin, horizontal=T)
bwplot(log(Endotoxin), horizontal=T)
mean(log(Endotoxin))
sd(log(Endotoxin))
2.01(0.858)/sqrt(51)
2.01*(0.858)/sqrt(51)
6.917 +0.241
6.917 -0.241
3+2.05 * 7.32/(sqrt(29))
3-2.05 * 7.32/(sqrt(29))
t.test(weight, alternative = "greater")
t.test(weight, alternative = "two.sided")
knitr::opts_chunk$set(echo = TRUE)
weight <- c(1.7, 11.7, -1.4, 0.7, 6.1, -0.8, -0.1, 1.1, 2.4, -0.7, -4.0, 12.6, -3.5, 20.9,
1.9, 14.9, -9.3, 3.9, 3.5, 2.1, 0.1, 17.1, 1.4, 15.4, -7.6, -0.3, -0.7,1.6, -3.7)
mean(weight)
sd(weight)
3/(7.32/sqrt(29))
3+2.05 * 7.32/(sqrt(29))
3-2.05 * 7.32/(sqrt(29))
t.test(weight, alternative = "greater")
t.test(weight, alternative = "two.sided")
download.file("http://www.openintro.org/stat/data/bdims.RData", destfile = "bdims.RData")
load("bdims.RData")
library(mosaic)
mdims = subset(bdims, sex == 1)
fdims = subset(bdims, sex == 0)
population = fdims$hgt
mu = mean(population); mu
sigma = sd(population); sigma
histogram(population, fit="normal", nint=15, xlab="Women's height (cm)")
samp = do(100) * favstats(sample(population, size = 5))
head(samp)
samp = transform(samp, lower = mean - 1.96 * sigma/sqrt(4))
samp = transform(samp, upper = mean + 1.96 * sigma/sqrt(4))
head(samp)
panel.ci = function (x, y, mu, data2, ...) {
panel.xyplot(x, y, ...)
good = subset(data2, upper > mu & lower < mu)
bad = subset(data2, upper < mu | lower > mu)
with(good, panel.arrows(lower, .index, upper, .index, angle=90, length = 0.05, ends="both"))
with(bad, panel.arrows(lower, .index, upper, .index, angle=90, length = 0.05, ends="both", col="red", lwd=3))
panel.abline(v=mu, lty=2)
}
plot_ci = function (df, mu, ...) {
space = 0.1 * (max(df$lower) - min(df$upper))
xyplot(.index ~ mean, data=df, data2 = df, panel=panel.ci, mu = mu, xlim = c(min(df$lower) - space, max(df$upper) + space), ylab = NULL)
}
plot_ci(samp, mu = mean(population))
knitr::opts_chunk$set(echo = TRUE)
weight <- c(1.7, 11.7, -1.4, 0.7, 6.1, -0.8, -0.1, 1.1, 2.4, -0.7, -4.0, 12.6, -3.5, 20.9,
1.9, 14.9, -9.3, 3.9, 3.5, 2.1, 0.1, 17.1, 1.4, 15.4, -7.6, -0.3, -0.7,1.6, -3.7)
mean(weight)
sd(weight)
3/(7.32/sqrt(29))
3+2.05 * 7.32/(sqrt(29))
3-2.05 * 7.32/(sqrt(29))
t.test(weight, alternative = "greater")
t.test(weight, alternative = "two.sided")
download.file("http://www.openintro.org/stat/data/bdims.RData", destfile = "bdims.RData")
load("bdims.RData")
library(mosaic)
mdims = subset(bdims, sex == 1)
fdims = subset(bdims, sex == 0)
population = fdims$hgt
mu = mean(population); mu
sigma = sd(population); sigma
histogram(population, fit="normal", nint=15, xlab="Women's height (cm)")
samp = do(100) * favstats(sample(population, size = 5))
head(samp)
11 + 13
test
#### Headers ####
##### Numeric #####
sample_size <- 100
# 6/14/23
#### Header ####
#### Variables ####
##### Numeric #####
sample_size <- 100
##### Characters #####
name <- "Clarissa"
(())no
bool_t <- TRUE
not bool_t
!bool_t
bool_t||!bool)t
bool_t||!bool_t
bool_t || !bool_t
bool_t & !bool_t
numbers <- c(33, 11, 232, 0.001)
numbers[1]
numbers[0]
numbers[-1]
numbers[1:3]
numbers[5:3]
numbers[4:3]
numbers[1:5:2]
groups_string <- c("Treatment1", "Treatment1", "Treatment2", "Control")
group <- factor(c("Treatment1", "Treatment1", "Treatment2", "Control"))
group
require(sjPlot)
install.packages("minqa", repos = "https://cran.rstudio.com/")
install.packages("RcppEigen", repos = "https://cran.rstudio.com/")
require(dplyr)
require(ggplot2)
require(lme4)
require(lmerTest)
require(sjPlot)
require(magrittr)
5+5
5+"noa"
5+"5"
"noa"+"noa"
5*5
"noa" *5
["noa"]*5
c("noa")*5
1-5
5/4
month.name
!month
?month
??month
# Setup -------------------------------------------------------------------
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'tidyverse', 'RColorBrewer', 'extrafont',
'this.path', 'brms', 'bayestestR')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
# color palettes
exp_control <- c("#F37121", "#4793AF")
exp_neutral_control <- c("#F37121", "#D3D3D3", "#4793AF")
effect_no <- c("#e74c3c", "#D3D3D3")
theme_custom <- function() {
theme_minimal(base_family = "Optima") +
theme(
axis.text.x = element_text(size = 15, margin = margin(t = 0, r = 0, b = 0, l = 1)),
axis.text.y = element_text(size = 15),
axis.title.x = element_text(size = 15),
axis.title.y = element_text(size = 15),
plot.title = element_text(size = 18, face = "bold"),
legend.text = element_text(size = 15),
legend.title = element_text(size = 15),
strip.text = element_text(size = 15),
aspect.ratio = 1,  # Set the aspect ratio here
panel.grid.major.x = element_blank(),  # Remove major vertical grid lines
panel.grid.minor.x = element_blank()   # Remove minor vertical grid lines
)
}
se = function(x) {return(sd(x, na.rm = T) / sqrt(sum(!is.na(x))))}
se.prop = function(x) {return(sqrt(mean(x, na.rm = T) * (1-mean(x, na.rm = T)) / sum(!is.na(x))))}
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
dodge <- position_dodge(width=0.9)
default_priors <- set_prior("normal(0,1)", class = 'b')
hindsight_data = data %>%
filter(task_name == "hindsight effect")%>%
filter(stimulus != "comprehension") %>%
mutate(choice = as.numeric(choice))
# Setup -------------------------------------------------------------------
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
pkg.names = c('ggplot2', 'tidyverse', 'RColorBrewer', 'extrafont',
'this.path', 'brms', 'bayestestR')
p_load(char = pkg.names)
setwd(here())
set.seed(123)
# color palettes
exp_control <- c("#F37121", "#4793AF")
exp_neutral_control <- c("#F37121", "#D3D3D3", "#4793AF")
effect_no <- c("#e74c3c", "#D3D3D3")
theme_custom <- function() {
theme_minimal(base_family = "Optima") +
theme(
axis.text.x = element_text(size = 15, margin = margin(t = 0, r = 0, b = 0, l = 1)),
axis.text.y = element_text(size = 15),
axis.title.x = element_text(size = 15),
axis.title.y = element_text(size = 15),
plot.title = element_text(size = 18, face = "bold"),
legend.text = element_text(size = 15),
legend.title = element_text(size = 15),
strip.text = element_text(size = 15),
aspect.ratio = 1,  # Set the aspect ratio here
panel.grid.major.x = element_blank(),  # Remove major vertical grid lines
panel.grid.minor.x = element_blank()   # Remove minor vertical grid lines
)
}
se = function(x) {return(sd(x, na.rm = T) / sqrt(sum(!is.na(x))))}
se.prop = function(x) {return(sqrt(mean(x, na.rm = T) * (1-mean(x, na.rm = T)) / sum(!is.na(x))))}
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
>>>>>>> Stashed changes
dodge <- position_dodge(width=0.9)
default_priors <- set_prior("normal(0,1)", class = 'b')
# Load data ---------------------------------------------------------------
data <- read.csv('pilot3_data.csv') %>%
filter(subject != "") %>%
arrange(subject, task_name) %>%
mutate(factor = factor(factor, c("Factor-Included", "Factor-Excluded"), c("experience", "control")))
subjects_all = data %>%
pull(subject) %>%
unique()
#find subjects who need to be excluded
attention_exclude <- data %>%
filter((`task_name` == "attention check 2" & `auxiliary_info1` == "Failure") |
(`task_name` == "attention check 3" & `auxiliary_info1` == "Incorrect")) %>%
pull(subject)
events <- read.csv('pilot3_browser_events.csv') %>%
arrange(subject)
events_subj <- events %>%
filter(browser_event == "blur") %>%
group_by(subject) %>%
summarize(blurs = n())
ggplot(events_subj, aes(x = blurs)) +
geom_histogram(binwidth = 1, color = "black") +
labs(title = "Blur Histogram", x = "Number of Blurs", y = "Count") +
theme_custom()
tab_away_exclude <- events_subj %>%
filter(blurs > 20) %>%
pull(subject)
demographics <- read.csv('pilot3_demographics.csv') %>%
arrange(subject) %>%
mutate(total_time = total_time/60000)
ggplot(demographics, aes(x = total_time)) +
geom_histogram(fill = "skyblue", color = "black") +
labs(title = "Time Histogram", x = "Minutes", y = "Count") +
theme_custom()
print(median(demographics$total_time))
to_exclude <- union(attention_exclude, tab_away_exclude)
number_subjects <- n_distinct(data$subject)
number_to_exclude <- length(to_exclude)
print(number_subjects)
print(number_to_exclude)
data <- data %>%
filter(!subject %in% to_exclude)
#font_import(pattern = "Optima", prompt = FALSE)
loadfonts(device = "pdf")
<<<<<<< Updated upstream
# Affect heuristic ----
affect_data = data %>%
filter(task_name == "affect heuristic")%>%
mutate(choice = as.numeric(choice))
summary_affect_data <- affect_data %>%
group_by(condition) %>%
mutate(condition = factor(condition, levels = c("With passage", "without passage"))) %>%
=======
# Hindsight ----
hindsight_data = data %>%
filter(task_name == "hindsight effect")%>%
filter(stimulus != "comprehension") %>%
mutate(choice = as.numeric(choice))
summary_hindsight_data <- hindsight_data %>%
group_by(condition) %>%
mutate(condition = factor(condition, levels = c("knowledge of outcome", "no knowledge of outcome"))) %>%
>>>>>>> Stashed changes
summarize(
mean_choice = mean(choice),
se_choice = se(choice),
count = n()
)
<<<<<<< Updated upstream
ggplot(summary_affect_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice), width = 0.2) +
labs(title = "Affect", x = "Condition", y = "How beneficial is natural gas") +
=======
ggplot(summary_hindsight_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice), width = 0.2) +
labs(title = "Hindsight", x = "Condition", y = "Percent Likelihood of British Victory") +
>>>>>>> Stashed changes
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom()+
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
<<<<<<< Updated upstream
affect_analysis = brm(choice ~ factor,
data = affect_data %>% mutate(choice = scale(choice)),
save_pars = save_pars(group = F),
prior = default_priors)
summarise_draws(affect_analysis)
check_divergences(affect_analysis$fit)
summary(affect_analysis)
hdi(affect_analysis)
# Power analysis (b/c affect heuristic is the smallest effect size)
#
# sample_sizes = c(300)
# num_runs_per = 10
# numCores = 5
# registerDoParallel(numCores)
#
# for (i in 1:length(sample_sizes)) {
#   sample_size = sample_sizes[i]
#
#   new_data_template = affect_data %>%
#     distinct(subject) %>%
#     slice_sample(n = sample_size, replace = T) %>%
#     group_by(subject) %>%
#     mutate(instance = row_number()) %>%
#     ungroup() %>%
#     left_join(affect_data, by = 'subject') %>%
#     mutate(subject = str_c(subject, instance, sep = "_"))
#
#   post_draws = posterior_predict(affect_analysis,
#                                  newdata = new_data_template,
#                                  ndraws = num_runs_per,
#                                  allow_new_levels = T)
#
#   results = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
#     new_data = new_data_template
#     new_data$introspect_rating = t(post_draws)[,j]
#
#     power_analysis = brm(choice ~ factor,
#                          data = affect_data,
#                          save_pars = save_pars(group = F),
#                          prior = default_priors)
#
#     power_analysis_hdi = bayestestR::hdi(power_analysis)
#     coef_estimate = summary(power_analysis)$fixed$Estimate[2]
#     hdi_high = power_analysis_hdi$CI_high[2]
#     hdi_low = power_analysis_hdi$CI_low[2]
#     list(coef_estimate, hdi_low, hdi_high)
#   }
#
#   results_df <- as.data.frame(results)
#   results_df = data.frame(lapply(results_df, unlist))
#   colnames(results_df) <- c("coef_estimate", "hdi_low", "hdi_high")
#   rownames(results_df) <- paste0("Run_", 1:num_runs_per)
#   results_all[[i]] = results_df %>%
#     mutate(hdi_width = hdi_high - hdi_low,
#            hdi_significant = hdi_low > .05)
# }
# Hindsight ----
=======
hindsight_analysis = brm(choice ~ factor,
data = hindsight_data,
save_pars = save_pars(group = F),
prior = default_priors)
summary(hindsight_analysis)
hdi(hindsight_analysis)
hindsight_data %>% count(condition)
pp_check(hindsight_analysis)
View(hindsight_data)
ggplot(summary_hindsight_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice), width = 0.2) +
labs(title = "Hindsight", x = "Condition", y = "Percent Likelihood of British Victory") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom()+
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
summary(hindsight_analysis)
ggplot(summary_hindsight_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity", position = "dodge", alpha = 0.7) +  # Bar chart with transparency
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice),
width = 0.2) +  # Error bars
geom_jitter(data = hindsight_data, aes(x = condition, y = choice),
width = 0.2, alpha = 0.6, color = "black", size = 2) +  # Individual data points
labs(title = "Hindsight", x = "Condition", y = "Percent Likelihood of British Victory") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom() +
scale_fill_manual(values = exp_control) +
guides(fill = FALSE) +
scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
t_test_result <- t.test(choice ~ condition, data = hindsight_data, var.equal = TRUE)
print(t_test_result$p.value)
>>>>>>> Stashed changes
hindsight_data = data %>%
filter(task_name == "hindsight effect")%>%
filter(stimulus != "comprehension") %>%
mutate(choice = as.numeric(choice))
summary_hindsight_data <- hindsight_data %>%
group_by(condition) %>%
mutate(condition = factor(condition, levels = c("knowledge of outcome", "no knowledge of outcome"))) %>%
summarize(
mean_choice = mean(choice),
se_choice = se(choice),
count = n()
)
ggplot(summary_hindsight_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice), width = 0.2) +
labs(title = "Hindsight", x = "Condition", y = "Percent Likelihood of British Victory") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom()+
<<<<<<< Updated upstream
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
hindsight_analysis = brm(choice ~ factor,
data = hindsight_data %>% mutate(choice = scale(choice)),
save_pars = save_pars(group = F),
prior = default_priors)
summary(hindsight_analysis)
hdi(hindsight_analysis)
# # Order effect ----
#
# primacy_data <- data %>%
#   filter(task_name == "primacy order") %>%
#   filter(choice != "")%>%
#   mutate(choice_fac = ifelse(choice == "car1",
#                          "chose primacy car",
#                          "chose other car")) %>%
#   mutate(choice_binary = as.numeric(choice_fac == "chose primacy car"))%>%
#   mutate(condition = factor(condition, levels = c("Factor-Included", "Factor-Excluded"), labels = c('experience', 'control')))
#
#
# summary_primacy_data <- primacy_data %>%
#   group_by(condition) %>%
#   summarize(
#     mean_choice = mean(choice_binary),
#     se_choice = se.prop(choice_binary),
#     count = n()
#   )
#
# summary_primacy_data2 <- primacy_data %>%
#   group_by(condition, choice) %>%
#   summarize(
#     count = n(),
#     .groups = 'drop'
#   )
#
# ggplot(summary_primacy_data, aes(x = condition, y = mean_choice, fill = condition)) +
#   geom_bar(stat = "identity") +
#   labs(title = "Choices of the primacy car", x = "Condition", y = "Percent who chose primacy car") +
#   geom_text(aes(label = paste0("n=", count)),
#             position = position_dodge(0.9), vjust = -0.5,
#             family = "Optima") +
#   theme_custom() +
#   scale_fill_manual(values = exp_control)+
#   guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
#
#
# primacy_analysis = brm(choice_binary ~ condition,
#                        data = primacy_data,
#                        family = 'bernoulli',
#                        save_pars = save_pars(group = F),
#                        prior = default_priors)
# summary(primacy_analysis)
# hdi(primacy_analysis, effects = 'all')
# Status quo ----
#When subjects were told the status quo,
#were they more likely to recommend the 70/30 allocation?
status_quo_data <- data %>%
filter(task_name == "status_quo") %>%
filter(stimulus != "comprehension") %>%
mutate(choice = ifelse(auxiliary_info1 == "Allocate 50% to auto safety and 50% to highway safety status quo: 50/50",
"status quo",
choice)) %>%
mutate(choice_binary = as.numeric(choice == "status quo"))%>%
mutate(condition = factor(condition, levels = c("Factor-Included", "Factor-Excluded")))
summary_status_quo_data <- status_quo_data %>%
group_by(condition) %>%
summarize(
mean_choice = mean(choice_binary),
se_choice = se.prop(choice_binary),
count = n()
)
ggplot(summary_status_quo_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
labs(title = "Choices to continue the status quo", x = "Condition", y = "Percent subjects who recommended the status quo") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom() +
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
status_quo_analysis = brm(choice_binary ~ condition,
data = status_quo_data,
family = 'bernoulli',
save_pars = save_pars(group = F),
prior = default_priors)
summary(status_quo_analysis)
hdi(status_quo_analysis, effects = 'all')
# Sunk cost ----
sunk_cost_data <- data %>%
filter(task_name == "sunk_cost2 effect") %>%
mutate(switched = choice == "Don't Continue Investing",
switched.num = as.numeric(switched))
percentage_sunk_cost_data <- sunk_cost_data %>%
group_by(condition) %>%
mutate(condition = factor(condition, levels = c("Sunk Cost", "No Sunk Cost"))) %>%
summarize(
total_in_condition = n(),  # Total number of subjects in each condition
switched_count = sum(choice == "Don't Continue Investing")  # Count who chose "Solar-powered pump"
) %>%
mutate(percentage_switched = (switched_count / total_in_condition) * 100)
ggplot(percentage_sunk_cost_data, aes(x = condition, y = percentage_switched, fill = condition)) +
geom_bar(stat = "identity") +
labs(title = "Percentage Who Stopped Investing", x = "Condition", y = "Percentage of Choices to Stop Investing") +
geom_text(aes(label = paste0("n=", total_in_condition)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom()+
scale_fill_manual(values = exp_control)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
sunk_cost_analysis = brm(switched.num ~ condition,
data = sunk_cost_data,
family = 'bernoulli',
save_pars = save_pars(group = F),
prior = default_priors)
summary(sunk_cost_analysis)
hdi(sunk_cost_analysis, effects = 'all')
# Save image --------------------------------------------------------------
save.image('pilot3_output.rdata')
summary(affect_analysis)
hdi(affect_analysis)
summary(hindsight_analysis)
hdi(hindsight_analysis)
summary(status_quo_analysis)
hdi(status_quo_analysis)
summary(sunk_cost_analysis)
hdi(sunk_cost_analysis)
rm(list=ls())
load("/Users/am9578/My Drive/Psychology/Projects/menagerie/noa_git/menagerie/analysis/osf/pilot1/pilot1_output.rdata")
summary(analysis.anchor)
summary(analysis.avail)
summary(analysis.cause)
summary(analysis.decoy)
summary(analysis.belief)
summary(analysis.mee)
rm(list=ls())
load("/Users/am9578/My Drive/Psychology/Projects/menagerie/noa_git/menagerie/analysis/osf/pilot2/pilot2_output.rdata")
summary(halo_analysis)
hdi(halo_analysis, effects = 'all')
hdi(halo_analysis, effects = 'all')
halo_data_choices$condition
halo_data <- data %>%
filter(task_name == "halo") %>%
mutate(choice = as.numeric(choice),
auxiliary_info1 = as.numeric(auxiliary_info1))
halo_data_choices = halo_data %>%
filter(stimulus != "") %>%
mutate(
condition = case_when(
grepl("img/U", stimulus) ~ "unattractive",
grepl("img/A", stimulus) ~ "attractive",
grepl("img/M", stimulus) ~ "average",
TRUE ~ condition
),
condition = factor(condition, c('attractive', 'average', 'unattractive'))
)
halo_summary <- halo_data_choices %>%
group_by(condition) %>%
summarize(
mean_choice = mean(choice),
se_choice = se(choice),
mean_attractiveness = mean(auxiliary_info1, na.rm = T),
se_attractiveness = se(auxiliary_info1),
count = n()
)
# manipulation check
ggplot(halo_summary, aes(x = condition, y = mean_attractiveness, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_attractiveness - se_attractiveness, ymax = mean_attractiveness + se_attractiveness), width = 0.2) +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
labs(title = "Average Persuasiveness by Condition", x = "Condition", y = "Average Persuasiveness") +
theme_custom()+
scale_fill_manual(values = exp_neutral_control)+
guides(fill = FALSE)
# actual effect
ggplot(halo_summary, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice), width = 0.2) +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
labs(title = "Average Persuasiveness by Attractiveness", x = "Condition", y = "Average Choice") +
theme_custom()+
scale_fill_manual(values = exp_neutral_control)+
guides(fill = "none")+
scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
# bayesian analysis
halo_analysis = brm(choice ~ condition + (1 | subject),
data = halo_data_choices %>% mutate(choice = scale(choice)),
prior = default_priors,
save_pars = save_pars(group = F),
cores = 4,
control = list(adapt_delta = 0.95))
summary(halo_analysis)
hdi(halo_analysis, effects = 'all')
summary(illusory_analysis)
hdi(illusory_analysis)
summary(omission_analysis)
summary(recognition_analysis)
hdi(recognition_analysis)
summary(reference_analysis)
summary(representativeness_analysis)
rm(list=ls())
sample_sizes = c(300)
num_runs_per = 10
numCores = 5
registerDoParallel(numCores)
results_all = vector(mode = 'list', length = length(sample_sizes))
for (i in 1:length(sample_sizes)) {
sample_size = sample_sizes[i]
new_data_template = affect_data %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(affect_data, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_"))
post_draws = posterior_predict(affect_analysis,
newdata = new_data_template,
ndraws = num_runs_per,
allow_new_levels = T)
results = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
new_data = new_data_template
new_data$introspect_rating = t(post_draws)[,j]
power_analysis = brm(choice ~ factor,
data = affect_data %>% mutate(choice = scale(choice)),
save_pars = save_pars(group = F),
prior = default_priors)
power_analysis_hdi = bayestestR::hdi(power_analysis)
coef_estimate = summary(power_analysis)$fixed$Estimate[2]
hdi_high = power_analysis_hdi$CI_high[2]
hdi_low = power_analysis_hdi$CI_low[2]
list(coef_estimate, hdi_low, hdi_high)
}
results_df <- as.data.frame(results)
results_df = data.frame(lapply(results_df, unlist))
colnames(results_df) <- c("coef_estimate", "hdi_low", "hdi_high")
rownames(results_df) <- paste0("Run_", 1:num_runs_per)
results_all[[i]] = results_df %>%
mutate(hdi_width = hdi_high - hdi_low,
hdi_significant = hdi_low > .05)
}
load("/Users/am9578/My Drive/Psychology/Projects/menagerie/noa_git/menagerie/analysis/osf/pilot3/pilot3_output.rdata")
sample_sizes = c(300)
num_runs_per = 10
numCores = 5
registerDoParallel(numCores)
results_all = vector(mode = 'list', length = length(sample_sizes))
for (i in 1:length(sample_sizes)) {
sample_size = sample_sizes[i]
new_data_template = affect_data %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(affect_data, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_"))
post_draws = posterior_predict(affect_analysis,
newdata = new_data_template,
ndraws = num_runs_per,
allow_new_levels = T)
results = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
new_data = new_data_template
new_data$introspect_rating = t(post_draws)[,j]
power_analysis = brm(choice ~ factor,
data = affect_data %>% mutate(choice = scale(choice)),
save_pars = save_pars(group = F),
prior = default_priors)
power_analysis_hdi = bayestestR::hdi(power_analysis)
coef_estimate = summary(power_analysis)$fixed$Estimate[2]
hdi_high = power_analysis_hdi$CI_high[2]
hdi_low = power_analysis_hdi$CI_low[2]
list(coef_estimate, hdi_low, hdi_high)
}
results_df <- as.data.frame(results)
results_df = data.frame(lapply(results_df, unlist))
colnames(results_df) <- c("coef_estimate", "hdi_low", "hdi_high")
rownames(results_df) <- paste0("Run_", 1:num_runs_per)
results_all[[i]] = results_df %>%
mutate(hdi_width = hdi_high - hdi_low,
hdi_significant = hdi_low > .05)
}
results_all
sample_sizes = c(300)
num_runs_per = 10
numCores = 5
registerDoParallel(numCores)
results_all = vector(mode = 'list', length = length(sample_sizes))
for (i in 1:length(sample_sizes)) {
sample_size = sample_sizes[i]
new_data_template = affect_data %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(affect_data, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_"))
post_draws = posterior_predict(affect_analysis,
newdata = new_data_template,
ndraws = num_runs_per,
allow_new_levels = T)
results = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
new_data = new_data_template
new_data$introspect_rating = t(post_draws)[,j]
power_analysis = brm(choice ~ factor,
data = new_data %>% mutate(choice = scale(choice)),
save_pars = save_pars(group = F),
prior = default_priors)
power_analysis_hdi = bayestestR::hdi(power_analysis)
coef_estimate = summary(power_analysis)$fixed$Estimate[2]
hdi_high = power_analysis_hdi$CI_high[2]
hdi_low = power_analysis_hdi$CI_low[2]
list(coef_estimate, hdi_low, hdi_high)
}
results_df <- as.data.frame(results)
results_df = data.frame(lapply(results_df, unlist))
colnames(results_df) <- c("coef_estimate", "hdi_low", "hdi_high")
rownames(results_df) <- paste0("Run_", 1:num_runs_per)
results_all[[i]] = results_df %>%
mutate(hdi_width = hdi_high - hdi_low,
hdi_significant = hdi_low > .05)
}
results_all
sample_sizes = c(150, 200)
num_runs_per = 100
numCores = 5
registerDoParallel(numCores)
results_all = vector(mode = 'list', length = length(sample_sizes))
for (i in 1:length(sample_sizes)) {
sample_size = sample_sizes[i]
new_data_template = affect_data %>%
distinct(subject) %>%
slice_sample(n = sample_size, replace = T) %>%
group_by(subject) %>%
mutate(instance = row_number()) %>%
ungroup() %>%
left_join(affect_data, by = 'subject') %>%
mutate(subject = str_c(subject, instance, sep = "_"))
post_draws = posterior_predict(affect_analysis,
newdata = new_data_template,
ndraws = num_runs_per,
allow_new_levels = T)
results = foreach(j = 1:num_runs_per, .combine = "rbind") %dopar% {
new_data = new_data_template
new_data$introspect_rating = t(post_draws)[,j]
power_analysis = brm(choice ~ factor,
data = new_data %>% mutate(choice = scale(choice)),
save_pars = save_pars(group = F),
prior = default_priors)
power_analysis_hdi = bayestestR::hdi(power_analysis)
coef_estimate = summary(power_analysis)$fixed$Estimate[2]
hdi_high = power_analysis_hdi$CI_high[2]
hdi_low = power_analysis_hdi$CI_low[2]
list(coef_estimate, hdi_low, hdi_high)
}
results_df <- as.data.frame(results)
results_df = data.frame(lapply(results_df, unlist))
colnames(results_df) <- c("coef_estimate", "hdi_low", "hdi_high")
rownames(results_df) <- paste0("Run_", 1:num_runs_per)
results_all[[i]] = results_df %>%
mutate(hdi_width = hdi_high - hdi_low,
hdi_significant = hdi_low > .05)
}
results_all
save.image('pilot3_output.rdata')
=======
scale_fill_manual(values = in_and_ex)+
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
hindsight_data = data %>%
filter(task_name == "hindsight effect")%>%
filter(stimulus != "comprehension") %>%
mutate(choice = as.numeric(choice))
summary_hindsight_data <- hindsight_data %>%
group_by(condition) %>%
mutate(condition = factor(condition, levels = c("knowledge of outcome", "no knowledge of outcome"))) %>%
summarize(
mean_choice = mean(choice),
se_choice = se(choice),
count = n()
)
ggplot(summary_hindsight_data, aes(x = condition, y = mean_choice, fill = condition)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = mean_choice - se_choice, ymax = mean_choice + se_choice), width = 0.2) +
labs(title = "Hindsight", x = "Condition", y = "Percent Likelihood of British Victory") +
geom_text(aes(label = paste0("n=", count)),
position = position_dodge(0.9), vjust = -0.5,
family = "Optima") +
theme_custom()+
scale_fill_manual(values = exp_control) +
guides(fill = FALSE)+   scale_x_discrete(labels = function(x) str_wrap(x, width = 14))
hindsight_analysis = brm(choice ~ factor,
data = hindsight_data,
save_pars = save_pars(group = F))
summary(hindsight_analysis)
hdi(hindsight_analysis)
>>>>>>> Stashed changes
